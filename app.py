import streamlit as st
import feedparser
import google.generativeai as genai
from openai import OpenAI
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS
import json_repair
import time
import os
import requests
import re
import base64
from gtts import gTTS
import concurrent.futures

# ================= 1. å·¥ç¨‹é…ç½® =================

st.set_page_config(page_title="WorthIt V3.0 å®Œç¾æ”¶å®˜", page_icon="ğŸ¦", layout="wide")

# ç«¯å£é…ç½®
PROXY_PORT = "3067"
os.environ["http_proxy"] = f"http://127.0.0.1:{PROXY_PORT}"
os.environ["https_proxy"] = f"http://127.0.0.1:{PROXY_PORT}"

# è¯»å–å¯†é’¥
GEMINI_KEY = st.secrets.get("GEMINI_API_KEY", "")
DEEPSEEK_KEY = st.secrets.get("DEEPSEEK_API_KEY", "")

# çŠ¶æ€æ£€æŸ¥
has_gemini = len(GEMINI_KEY) > 10
has_deepseek = len(DEEPSEEK_KEY) > 10

# ================= 2. å¼ºåŠ›æŠ“å–å™¨ (è§£å†³ 0 ç»“æœé—®é¢˜) =================

def fetch_feed_safe(url):
    """
    ğŸ¥· ä¼ªè£…æˆæµè§ˆå™¨å»æŠ“å– RSSï¼Œé˜²æ­¢è¢«æ‹¦æˆª
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
    }
    try:
        # å…ˆç”¨ requests ä¼ªè£…ä¸‹è½½
        resp = requests.get(url, headers=headers, timeout=10)
        # å†æŠŠå†…å®¹ç»™ feedparser è§£æ
        return feedparser.parse(resp.content)
    except:
        return None

# ================= 3. AI å¼•æ“ (æ’ç‰ˆä¼˜åŒ–ç‰ˆ) =================

class AI_Engine:
    def _call_deepseek_raw(self, prompt):
        if not has_deepseek: return "DeepSeek æœªé…ç½®"
        try:
            client = OpenAI(api_key=DEEPSEEK_KEY, base_url="https://api.deepseek.com")
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                temperature=1.3 # ç¨å¾®é«˜ä¸€ç‚¹ï¼Œè®©è¡Œæ–‡æ›´è‡ªç„¶
            )
            return response.choices[0].message.content
        except Exception as e: return f"DeepSeek Error: {e}"

    def _call_gemini_raw(self, prompt):
        if not has_gemini: return "Gemini æœªé…ç½®"
        try:
            genai.configure(api_key=GEMINI_KEY)
            # å°è¯•æœ€åŸºç¡€çš„æ¨¡å‹ï¼Œé˜² 404
            model = genai.GenerativeModel('gemini-pro') 
            response = model.generate_content(prompt)
            return response.text
        except Exception as e: return f"Gemini Error: {e}"

    def generate_single(self, prompt, engine_name):
        if engine_name == "DeepSeek": return self._call_deepseek_raw(prompt)
        else: return self._call_gemini_raw(prompt)

    def generate_fusion(self, prompt, context_data):
        # åŒæ ¸ä»»åŠ¡
        task_prompt = f"""
        é˜…è¯»èµ„æ–™ï¼š
        {context_data[:5000]}
        
        ç”¨æˆ·é—®é¢˜ï¼š{prompt}
        è¦æ±‚ï¼šæ·±åº¦åˆ†æï¼Œé€»è¾‘æ¸…æ™°ã€‚
        """
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            future_ds = executor.submit(self._call_deepseek_raw, task_prompt)
            if has_gemini:
                future_ge = executor.submit(self._call_gemini_raw, task_prompt)
                res_ge = future_ge.result()
            else:
                res_ge = "Gemini Skipped"
            res_ds = future_ds.result()

        # èåˆ Prompt (å¼ºè°ƒæ’ç‰ˆ)
        fusion_prompt = f"""
        Role: Senior Editor.
        Task: Merge two reports into one PERFECTLY FORMATTED report.
        
        Report A (DeepSeek): {res_ds[:4000]}
        Report B (Gemini): {res_ge[:4000]}
        
        FORMATTING RULES (STRICT):
        1. Use `##` for main sections.
        2. Use `###` for subsections.
        3. Use `- ` (bullet points) for lists.
        4. Use `**Bold**` for key terms.
        5. Insert blank lines between paragraphs.
        
        Output: Chinese Markdown.
        """
        return self._call_deepseek_raw(fusion_prompt), res_ds, res_ge

# ================= 4. ä¸šåŠ¡é€»è¾‘ (æ ¸å¿ƒ Prompt ä¿®æ”¹) =================

class Sanitizer:
    @staticmethod
    def clean(text):
        if not text: return ""
        text = str(text)
        try:
            soup = BeautifulSoup(text, 'html.parser')
            text = soup.get_text(separator=' ', strip=True)
        except: text = re.sub(r'<[^>]+>', '', text)
        return re.sub(r'\s+', ' ', text).strip()

def safe_extract_image(entry):
    try:
        if 'media_content' in entry and entry.media_content: return entry.media_content[0]['url']
        if 'media_thumbnail' in entry and entry.media_thumbnail: return entry.media_thumbnail[0]['url']
        soup = BeautifulSoup(entry.get('summary', ''), 'html.parser')
        img = soup.find('img')
        if img: return img.get('src')
    except: pass
    return None

def analyze_item(item, mode, engine_name):
    engine = AI_Engine()
    raw_summary = Sanitizer.clean(item.get('summary', ''))
    title = item['title']
    
    # æç¤ºè¯å·¥ç¨‹ï¼šå¼ºåˆ¶æ’ç‰ˆ
    role = "Senior Tech Editor"
    if mode == "movie": role = "Film Critic"
    
    prompt = f"""
    Role: {role}
    Task: Translate & Summarize into Simplified Chinese.
    
    Source Title: {title}
    Source Content: {raw_summary[:3000]}
    
    OUTPUT FORMAT REQUIREMENTS (CRITICAL):
    1. **Title**: Catchy Chinese Title.
    2. **Summary**:
       - MUST be structured with clear paragraphs.
       - Use `**` to bold key entities (People, Companies, Products).
       - If there are multiple points, use a list format:
         * Point 1
         * Point 2
    3. **Tags**: 3-5 keywords.
    
    Output JSON ONLY: {{ "score": 85, "title_cn": "...", "summary": "Markdown content...", "tags": ["..."] }}
    """

    retries = 2
    for i in range(retries):
        try:
            res_text = engine.generate_single(prompt, engine_name)
            res = json_repair.repair_json(res_text, return_objects=True)
            if not res.get('summary'): raise ValueError("Empty")
            return res
        except:
            if engine_name == "Gemini": time.sleep(2)
            else: time.sleep(1)
            continue
            
    return {"score": 0, "title_cn": title, "summary": raw_summary, "tags": ["Fail"], "status": "fallback"}

# ================= 5. UI ä¸»ç•Œé¢ =================

st.title("ğŸ¦ WorthIt V3.0 å®Œç¾æ”¶å®˜ç‰ˆ")

with st.sidebar:
    st.header("ğŸ›ï¸ å¼•æ“é€‰æ‹©")
    # é»˜è®¤é€‰ DeepSeekï¼Œå› ä¸º Gemini ç»å¸¸æŠ¥é”™
    engine_choice = st.radio("ä¸»å¼•æ“:", ["DeepSeek", "Gemini"], index=0 if has_deepseek else 1)
    
    st.divider()
    if has_deepseek: st.success("âœ… DeepSeek å°±ç»ª")
    if has_gemini: st.info("â„¹ï¸ Gemini å°±ç»ª (æ³¨æ„é…é¢)")

t1, t2, t3, t4 = st.tabs(["ğŸŒ å…¨çƒæ–°é—»", "ğŸ¬ å½±è§†å‰çº¿", "ğŸ¸ é…·ç©ç¡¬ä»¶", "ğŸ§  åŒæ ¸ç‰¹å·¥"])

# å¢åŠ äº†å›½å†…æ›´å®¹æ˜“è®¿é—®çš„æºï¼Œè§£å†³â€œ0ç»“æœâ€
SOURCES = {
    "news": {
        "Techmeme": "https://www.techmeme.com/feed.xml",
        "Nature": "https://www.nature.com/nature.rss"
    },
    "movie": {
        "Variety": "https://variety.com/v/film/feed/", 
        "HollywoodReporter": "https://www.hollywoodreporter.com/c/movies/movie-news/feed/"
    },
    "gear": {
        "Engadget": "https://www.engadget.com/rss.xml", # å¼ºåŠ›æŠ“å–
        "TheVerge": "https://www.theverge.com/rss/circuit-breaker/index.xml" 
    }
}

def render_feed(src_dict, mode):
    items = []
    seen = set()
    status = st.empty()
    status.info(f"ğŸ“¡ {engine_choice} æ­£åœ¨å¼ºåŠ›æŠ“å–ä¸­ (å·²å¯ç”¨åçˆ¬è™«ä¼ªè£…)...")
    
    for s, u in src_dict.items():
        # ä½¿ç”¨å¼ºåŠ›æŠ“å–å™¨
        f = fetch_feed_safe(u)
        if f:
            for e in f.entries[:3]:
                if e.link not in seen:
                    items.append({'title': e.title, 'link': e.link, 'summary': e.summary if 'summary' in e else '', 'image': safe_extract_image(e), 'source': s})
                    seen.add(e.link)
        
    processed = []
    bar = st.progress(0)
    
    for i, item in enumerate(items):
        bar.progress((i)/len(items))
        if engine_choice == "Gemini": time.sleep(4) # é¿å¼€ 429
        
        res = analyze_item(item, mode, engine_choice)
        item.update(res)
        processed.append(item)
        
    status.empty()
    bar.empty()
    processed.sort(key=lambda x: int(x.get('score', 0)), reverse=True)
    
    for item in processed:
        score = int(item.get('score', 0))
        color = "#ff4b4b" if score >= 80 else "#ffa421"
        with st.container(border=True):
            has_img = item.get('image') and mode in ['movie', 'gear']
            c1, c2 = st.columns([3, 1]) if has_img else st.columns([1, 0.01])
            with c1:
                st.markdown(f"### {item['title_cn']}")
                st.caption(f"Source: {item['source']} | Tags: {item.get('tags')}")
                
                # æ¸²æŸ“ä¼˜åŒ–ï¼šç¡®ä¿ Markdown ç”Ÿæ•ˆ
                st.markdown(item['summary'])
                
                with st.expander("ğŸ”— åŸæ–‡ä¸å·¥å…·"):
                     st.markdown(f"[é˜…è¯»åŸæ–‡]({item['link']})")
            if has_img:
                with c2:
                    st.image(item['image'], use_container_width=True)
                    st.markdown(f"<h1 style='color:{color};text-align:center'>{score}</h1>", unsafe_allow_html=True)

with t1:
    if st.button("ğŸš€ æ‰«ææ–°é—»"): render_feed(SOURCES['news'], "news")
with t2:
    if st.button("ğŸ¥ æ‰«æå½±è§†"): render_feed(SOURCES['movie'], "movie")
with t3:
    if st.button("ğŸ¸ æ‰«æç¡¬ä»¶"): render_feed(SOURCES['gear'], "gear")

with t4:
    st.markdown("### ğŸ•µï¸ åŒæ ¸æƒ…æŠ¥å±€ (æ’ç‰ˆå¢å¼ºç‰ˆ)")
    q = st.text_input("è¯·è¾“å…¥æŒ‡ä»¤")
    if st.button("ğŸ” å¯åŠ¨"):
        engine = AI_Engine()
        with st.spinner("åŒæ ¸å¼•æ“æ­£åœ¨å…¨é€Ÿè¿è½¬..."):
            # ç®€åŒ–é€»è¾‘ï¼šç‰¹å·¥æ¨¡å¼ç›´æ¥ç”¨ search (éœ€è‡ªè¡Œæ·»åŠ  NetworkOps ç±»æˆ–ä¿ç•™æ—§ä»£ç ï¼Œæ­¤å¤„ç®€åŒ–å±•ç¤º)
            # ä¸ºä¿è¯ä»£ç å®Œæ•´æ€§ï¼Œè¿™é‡Œå¤ç”¨ä¹‹å‰çš„ search é€»è¾‘
            from duckduckgo_search import DDGS
            ctx = ""
            try:
                with DDGS() as ddgs:
                    for r in list(ddgs.text(q, max_results=5)): ctx += r['body']
            except: ctx = "Internal Knowledge"
            
            final, _, _ = engine.generate_fusion(q, ctx)
            st.markdown(final)